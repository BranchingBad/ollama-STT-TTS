[Models]
ollama_model = llama3
whisper_model = small.en
wakeword_model_path = models/jarvis_v2.onnx
piper_model_path = models/en_US-lessac-medium.onnx
ollama_host = http://localhost:11434

[Functionality]
wakeword = hey jarvis
wakeword_threshold = 0.20
vad_aggressiveness = 2
silence_seconds = 0.5
listen_timeout = 5.0
pre_buffer_ms = 400
system_prompt = You are a witty, intelligent voice assistant. Your brainpower is vast, but your output channel is tiny. All responses must be highly compressed: just one or two clever, concise sentences. Be witty, be accurate, be brief. No filler.
device_index = None
piper_output_device_index = 0
max_words_per_command = 80
whisper_device = cpu
whisper_compute_type = int8
whisper_avg_logprob = -1.0
whisper_no_speech_prob = 0.6
max_history_tokens = 2048
trim_wake_word = true

[Performance]
# Force garbage collection every N conversations
gc_interval = 10

# Enable memory profiling in debug mode
memory_profiling = false
