[Models]
ollama_model = llama3
whisper_model = small.en
wakeword_model_path = models/jarvis_v2.onnx
piper_model_path = models/en_US-lessac-medium.onnx
ollama_host = http://localhost:11434

[Functionality]
wakeword = hey jarvis
# Slightly higher threshold to reduce false positives
wakeword_threshold = 0.25

# VAD settings - balance between sensitivity and accuracy
vad_aggressiveness = 2

# More patient silence detection (0.7s instead of 0.5s)
silence_seconds = 0.7

# Timeout for initial speech detection
listen_timeout = 5.0

# Capture more audio before speech starts (600ms instead of 400ms)
pre_buffer_ms = 600

# System prompt - keep responses concise for voice
system_prompt = You are a witty, intelligent voice assistant. Your brainpower is vast, but your output channel is tiny. All responses must be highly compressed: just one or two clever, concise sentences. Be witty, be accurate, be brief. No filler.

# Audio device indices (None = use default)
device_index = None
piper_output_device_index = 0

# Maximum words allowed in a command
max_words_per_command = 80
max_phrase_duration = 15.0


# Whisper configuration
whisper_device = cpu
whisper_compute_type = int8

# More lenient Whisper thresholds to accept more transcriptions
# avg_logprob: higher (closer to 0) = better confidence
# Relaxed from -1.0 to -1.3 to accept lower confidence segments
whisper_avg_logprob = -1.3

# no_speech_prob: lower = more likely to be speech
# Relaxed from 0.6 to 0.75 to accept segments with higher no-speech probability
whisper_no_speech_prob = 0.75

# Chat history settings
max_history_tokens = 2048

# Larger audio buffer to prevent dropouts (300 instead of default 200)
audio_buffer_size = 300

# Trim wake word from transcription (recommended)
trim_wake_word = true

[Performance]
# Force garbage collection every N conversations
gc_interval = 10

# Enable memory profiling in debug mode (adds overhead)
memory_profiling = false